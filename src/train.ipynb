{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59a2dfd4-2075-4c59-9a86-a0639b71e3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/Prodigy/py36venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (26) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from vae import VAE \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, Dense, Lambda\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv(\"scaled_node_metric_data_combined.csv\")\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df.set_index(['Timestamp'], inplace=True)\n",
    "df_interpolated = df.interpolate(method='linear')\n",
    "df_interpolated = df_interpolated.dropna()\n",
    "unique_uuids = df_interpolated[\"nodeid\"].unique()\n",
    "uuid_to_float_mapping = {str(uuid_val): float(idx) for idx, uuid_val in enumerate(unique_uuids)}\n",
    "\n",
    "# Convert the UUIDs to floats in the DataFrame\n",
    "df_interpolated['nodeid'] = df_interpolated['nodeid'].map(uuid_to_float_mapping)\n",
    "X = df_interpolated.values\n",
    "input_dim = X.shape[1]\n",
    "intermediate_dim = int(input_dim / 2)\n",
    "latent_dim = int(input_dim / 3)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1), clip=True)\n",
    "x_train = pd.DataFrame(scaler.fit_transform(df_interpolated), columns=df_interpolated.columns, index=df_interpolated.index)\n",
    "\n",
    "\n",
    "vae = VAE(name=\"model\",input_dim=input_dim,intermediate_dim=intermediate_dim,latent_dim=latent_dim,\n",
    "                learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fee13fd-a325-4b18-8d51-26216a85b6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51521e30-3c11-4dc4-8f81-4bd1cbd7a8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116721 samples, validate on 12969 samples\n",
      "Epoch 1/1000\n",
      "116512/116721 [============================>.] - ETA: 0s - loss: 48.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/Prodigy/py36venv/lib/python3.6/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116721/116721 [==============================] - 8s 71us/sample - loss: 48.0732 - val_loss: 55.6703\n",
      "Epoch 2/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 15.9351 - val_loss: 50.1002\n",
      "Epoch 3/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 11.8638 - val_loss: 32.9297\n",
      "Epoch 4/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 9.3736 - val_loss: 27.8942\n",
      "Epoch 5/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 8.1495 - val_loss: 27.5191\n",
      "Epoch 6/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 7.4503 - val_loss: 26.9848\n",
      "Epoch 7/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 6.9947 - val_loss: 26.4578\n",
      "Epoch 8/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 6.6923 - val_loss: 25.8845\n",
      "Epoch 9/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 6.4941 - val_loss: 25.6918\n",
      "Epoch 10/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 6.3555 - val_loss: 25.1963\n",
      "Epoch 11/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 6.2588 - val_loss: 25.0202\n",
      "Epoch 12/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 6.1861 - val_loss: 24.9171\n",
      "Epoch 13/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 6.1093 - val_loss: 24.9527\n",
      "Epoch 14/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 6.0495 - val_loss: 24.8141\n",
      "Epoch 15/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.9901 - val_loss: 24.8867\n",
      "Epoch 16/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.9463 - val_loss: 24.8909\n",
      "Epoch 17/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.8972 - val_loss: 25.0330\n",
      "Epoch 18/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.8509 - val_loss: 24.7197\n",
      "Epoch 19/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.8117 - val_loss: 24.7550\n",
      "Epoch 20/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.7790 - val_loss: 24.7256\n",
      "Epoch 21/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.7435 - val_loss: 24.7565\n",
      "Epoch 22/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.7180 - val_loss: 24.6407\n",
      "Epoch 23/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.6971 - val_loss: 24.4309\n",
      "Epoch 24/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.6714 - val_loss: 24.4469\n",
      "Epoch 25/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.6650 - val_loss: 24.3619\n",
      "Epoch 26/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.6444 - val_loss: 24.3792\n",
      "Epoch 27/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.6330 - val_loss: 24.4167\n",
      "Epoch 28/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.6129 - val_loss: 24.3459\n",
      "Epoch 29/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.6062 - val_loss: 24.4147\n",
      "Epoch 30/1000\n",
      "116721/116721 [==============================] - 8s 72us/sample - loss: 5.5948 - val_loss: 24.3316\n",
      "Epoch 31/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.5782 - val_loss: 24.4263\n",
      "Epoch 32/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.5661 - val_loss: 24.4724\n",
      "Epoch 33/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.5698 - val_loss: 24.4369\n",
      "Epoch 34/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.5614 - val_loss: 24.4987\n",
      "Epoch 35/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.5536 - val_loss: 24.5716\n",
      "Epoch 36/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.5377 - val_loss: 24.5415\n",
      "Epoch 37/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.5428 - val_loss: 24.4485\n",
      "Epoch 38/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.5227 - val_loss: 24.7438\n",
      "Epoch 39/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.5261 - val_loss: 24.8193\n",
      "Epoch 40/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.5218 - val_loss: 24.8323\n",
      "Epoch 41/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.5066 - val_loss: 24.8628\n",
      "Epoch 42/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.5033 - val_loss: 24.9905\n",
      "Epoch 43/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.4984 - val_loss: 25.1288\n",
      "Epoch 44/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.4774 - val_loss: 25.3287\n",
      "Epoch 45/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.4707 - val_loss: 25.4260\n",
      "Epoch 46/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.4694 - val_loss: 25.7408\n",
      "Epoch 47/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.4540 - val_loss: 25.6767\n",
      "Epoch 48/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.4444 - val_loss: 25.9085\n",
      "Epoch 49/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.4409 - val_loss: 26.0501\n",
      "Epoch 50/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.4272 - val_loss: 26.4223\n",
      "Epoch 51/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.4100 - val_loss: 26.4436\n",
      "Epoch 52/1000\n",
      "116721/116721 [==============================] - 8s 66us/sample - loss: 5.4103 - val_loss: 26.8238\n",
      "Epoch 53/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.4032 - val_loss: 26.9359\n",
      "Epoch 54/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.3915 - val_loss: 27.0201\n",
      "Epoch 55/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.3844 - val_loss: 27.4390\n",
      "Epoch 56/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.3801 - val_loss: 27.4688\n",
      "Epoch 57/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.3720 - val_loss: 27.7066\n",
      "Epoch 58/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.3707 - val_loss: 27.6947\n",
      "Epoch 59/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.3604 - val_loss: 27.8996\n",
      "Epoch 60/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.3514 - val_loss: 28.1892\n",
      "Epoch 61/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.3538 - val_loss: 28.2519\n",
      "Epoch 62/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.3551 - val_loss: 28.4930\n",
      "Epoch 63/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.3491 - val_loss: 28.7893\n",
      "Epoch 64/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.3440 - val_loss: 28.8413\n",
      "Epoch 65/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.3338 - val_loss: 28.8133\n",
      "Epoch 66/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.3336 - val_loss: 29.2726\n",
      "Epoch 67/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.3327 - val_loss: 29.1470\n",
      "Epoch 68/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.3355 - val_loss: 29.7297\n",
      "Epoch 69/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.3276 - val_loss: 29.6868\n",
      "Epoch 70/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.3177 - val_loss: 29.6003\n",
      "Epoch 71/1000\n",
      "116721/116721 [==============================] - 8s 66us/sample - loss: 5.3174 - val_loss: 29.9366\n",
      "Epoch 72/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.3228 - val_loss: 29.9647\n",
      "Epoch 73/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.3144 - val_loss: 30.2064\n",
      "Epoch 74/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.3118 - val_loss: 30.2989\n",
      "Epoch 75/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.3092 - val_loss: 30.2283\n",
      "Epoch 76/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.3063 - val_loss: 30.4006\n",
      "Epoch 77/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.3013 - val_loss: 30.5357\n",
      "Epoch 78/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.3052 - val_loss: 30.4512\n",
      "Epoch 79/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.2960 - val_loss: 30.5724\n",
      "Epoch 80/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.2986 - val_loss: 30.6144\n",
      "Epoch 81/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.2957 - val_loss: 30.7570\n",
      "Epoch 82/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2918 - val_loss: 30.6990\n",
      "Epoch 83/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.2927 - val_loss: 30.9071\n",
      "Epoch 84/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2766 - val_loss: 31.0574\n",
      "Epoch 85/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2858 - val_loss: 30.9095\n",
      "Epoch 86/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2741 - val_loss: 31.0155\n",
      "Epoch 87/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.2725 - val_loss: 31.1086\n",
      "Epoch 88/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.2827 - val_loss: 31.3650\n",
      "Epoch 89/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.2697 - val_loss: 31.1921\n",
      "Epoch 90/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.2701 - val_loss: 30.9686\n",
      "Epoch 91/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2745 - val_loss: 31.1959\n",
      "Epoch 92/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.2706 - val_loss: 31.4183\n",
      "Epoch 93/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.2625 - val_loss: 31.3642\n",
      "Epoch 94/1000\n",
      "116721/116721 [==============================] - 8s 72us/sample - loss: 5.2678 - val_loss: 31.5006\n",
      "Epoch 95/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.2610 - val_loss: 31.5694\n",
      "Epoch 96/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2573 - val_loss: 31.5872\n",
      "Epoch 97/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2651 - val_loss: 31.7353\n",
      "Epoch 98/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2648 - val_loss: 31.5500\n",
      "Epoch 99/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2536 - val_loss: 31.8852\n",
      "Epoch 100/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2527 - val_loss: 31.6749\n",
      "Epoch 101/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.2618 - val_loss: 31.9662\n",
      "Epoch 102/1000\n",
      "116721/116721 [==============================] - 8s 72us/sample - loss: 5.2556 - val_loss: 32.0961\n",
      "Epoch 103/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2570 - val_loss: 31.9659\n",
      "Epoch 104/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2496 - val_loss: 31.9093\n",
      "Epoch 105/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2553 - val_loss: 32.1492\n",
      "Epoch 106/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2510 - val_loss: 32.2166\n",
      "Epoch 107/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2466 - val_loss: 32.0420\n",
      "Epoch 108/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2444 - val_loss: 32.1444\n",
      "Epoch 109/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2428 - val_loss: 32.3987\n",
      "Epoch 110/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.2476 - val_loss: 32.4035\n",
      "Epoch 111/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2400 - val_loss: 32.3668\n",
      "Epoch 112/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2371 - val_loss: 32.3626\n",
      "Epoch 113/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2380 - val_loss: 32.5227\n",
      "Epoch 114/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2362 - val_loss: 32.5539\n",
      "Epoch 115/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2464 - val_loss: 32.5692\n",
      "Epoch 116/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2379 - val_loss: 32.6611\n",
      "Epoch 117/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.2426 - val_loss: 32.8791\n",
      "Epoch 118/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.2352 - val_loss: 32.6708\n",
      "Epoch 119/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.2427 - val_loss: 32.9579\n",
      "Epoch 120/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2441 - val_loss: 33.2069\n",
      "Epoch 121/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2346 - val_loss: 33.2612\n",
      "Epoch 122/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2404 - val_loss: 33.3242\n",
      "Epoch 123/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2265 - val_loss: 33.3182\n",
      "Epoch 124/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2312 - val_loss: 33.2829\n",
      "Epoch 125/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2320 - val_loss: 33.4534\n",
      "Epoch 126/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2315 - val_loss: 33.4701\n",
      "Epoch 127/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2252 - val_loss: 33.5147\n",
      "Epoch 128/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2244 - val_loss: 33.7178\n",
      "Epoch 129/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2276 - val_loss: 33.8836\n",
      "Epoch 130/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2230 - val_loss: 33.8447\n",
      "Epoch 131/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2313 - val_loss: 33.8054\n",
      "Epoch 132/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2152 - val_loss: 33.9444\n",
      "Epoch 133/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2277 - val_loss: 34.1513\n",
      "Epoch 134/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2235 - val_loss: 34.1156\n",
      "Epoch 135/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2125 - val_loss: 34.1588\n",
      "Epoch 136/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2119 - val_loss: 34.2102\n",
      "Epoch 137/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2210 - val_loss: 34.4272\n",
      "Epoch 138/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2203 - val_loss: 34.3396\n",
      "Epoch 139/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.2096 - val_loss: 34.5698\n",
      "Epoch 140/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2186 - val_loss: 34.5294\n",
      "Epoch 141/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2107 - val_loss: 34.8537\n",
      "Epoch 142/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2164 - val_loss: 34.8464\n",
      "Epoch 143/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2150 - val_loss: 34.8031\n",
      "Epoch 144/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2082 - val_loss: 34.7983\n",
      "Epoch 145/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2134 - val_loss: 34.9023\n",
      "Epoch 146/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2188 - val_loss: 34.7975\n",
      "Epoch 147/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2019 - val_loss: 35.1394\n",
      "Epoch 148/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1962 - val_loss: 35.0329\n",
      "Epoch 149/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2042 - val_loss: 35.0646\n",
      "Epoch 150/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2049 - val_loss: 35.2674\n",
      "Epoch 151/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2003 - val_loss: 35.2054\n",
      "Epoch 152/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.2077 - val_loss: 35.2647\n",
      "Epoch 153/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1963 - val_loss: 35.2899\n",
      "Epoch 154/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.2015 - val_loss: 35.3260\n",
      "Epoch 155/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1970 - val_loss: 35.3124\n",
      "Epoch 156/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1948 - val_loss: 35.2615\n",
      "Epoch 157/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.1982 - val_loss: 35.5391\n",
      "Epoch 158/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1983 - val_loss: 35.3509\n",
      "Epoch 159/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1957 - val_loss: 35.5007\n",
      "Epoch 160/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1892 - val_loss: 35.6208\n",
      "Epoch 161/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1938 - val_loss: 35.5046\n",
      "Epoch 162/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1902 - val_loss: 35.7539\n",
      "Epoch 163/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1845 - val_loss: 35.6369\n",
      "Epoch 164/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1903 - val_loss: 35.6416\n",
      "Epoch 165/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1862 - val_loss: 35.5901\n",
      "Epoch 166/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1836 - val_loss: 35.6629\n",
      "Epoch 167/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1901 - val_loss: 35.7112\n",
      "Epoch 168/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1821 - val_loss: 35.6532\n",
      "Epoch 169/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1845 - val_loss: 35.7034\n",
      "Epoch 170/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.1819 - val_loss: 35.6833\n",
      "Epoch 171/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1787 - val_loss: 35.6475\n",
      "Epoch 172/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1836 - val_loss: 35.6678\n",
      "Epoch 173/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.1802 - val_loss: 35.6528\n",
      "Epoch 174/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1744 - val_loss: 35.6778\n",
      "Epoch 175/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1807 - val_loss: 35.5994\n",
      "Epoch 176/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1801 - val_loss: 35.5919\n",
      "Epoch 177/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1778 - val_loss: 35.6489\n",
      "Epoch 178/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1735 - val_loss: 35.6022\n",
      "Epoch 179/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.1747 - val_loss: 35.6533\n",
      "Epoch 180/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.1780 - val_loss: 35.5590\n",
      "Epoch 181/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1689 - val_loss: 35.5144\n",
      "Epoch 182/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1675 - val_loss: 35.6402\n",
      "Epoch 183/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1672 - val_loss: 35.4934\n",
      "Epoch 184/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1661 - val_loss: 35.5728\n",
      "Epoch 185/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.1687 - val_loss: 35.6588\n",
      "Epoch 186/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1644 - val_loss: 35.7434\n",
      "Epoch 187/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1610 - val_loss: 35.5304\n",
      "Epoch 188/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1625 - val_loss: 35.6523\n",
      "Epoch 189/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1622 - val_loss: 35.4810\n",
      "Epoch 190/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.1627 - val_loss: 35.6020\n",
      "Epoch 191/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1654 - val_loss: 35.5840\n",
      "Epoch 192/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1628 - val_loss: 35.4070\n",
      "Epoch 193/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1599 - val_loss: 35.5330\n",
      "Epoch 194/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.1596 - val_loss: 35.4784\n",
      "Epoch 195/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1586 - val_loss: 35.4700\n",
      "Epoch 196/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1569 - val_loss: 35.5505\n",
      "Epoch 197/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1599 - val_loss: 35.5281\n",
      "Epoch 198/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1594 - val_loss: 35.5797\n",
      "Epoch 199/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1586 - val_loss: 35.4501\n",
      "Epoch 200/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.1561 - val_loss: 35.5780\n",
      "Epoch 201/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1496 - val_loss: 35.5316\n",
      "Epoch 202/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1609 - val_loss: 35.7224\n",
      "Epoch 203/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1564 - val_loss: 35.6484\n",
      "Epoch 204/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1494 - val_loss: 35.5870\n",
      "Epoch 205/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1581 - val_loss: 35.7136\n",
      "Epoch 206/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1514 - val_loss: 35.6018\n",
      "Epoch 207/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1497 - val_loss: 35.5735\n",
      "Epoch 208/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1530 - val_loss: 35.5704\n",
      "Epoch 209/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1477 - val_loss: 35.5681\n",
      "Epoch 210/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1383 - val_loss: 35.6467\n",
      "Epoch 211/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1490 - val_loss: 35.4921\n",
      "Epoch 212/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1435 - val_loss: 35.6144\n",
      "Epoch 213/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1465 - val_loss: 35.5983\n",
      "Epoch 214/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1374 - val_loss: 35.6103\n",
      "Epoch 215/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1453 - val_loss: 35.7043\n",
      "Epoch 216/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.1475 - val_loss: 35.6141\n",
      "Epoch 217/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1419 - val_loss: 35.6048\n",
      "Epoch 218/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1473 - val_loss: 35.6470\n",
      "Epoch 219/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1444 - val_loss: 35.6826\n",
      "Epoch 220/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.1467 - val_loss: 35.6701\n",
      "Epoch 221/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1457 - val_loss: 35.7119\n",
      "Epoch 222/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.1375 - val_loss: 35.8097\n",
      "Epoch 223/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1326 - val_loss: 35.5963\n",
      "Epoch 224/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1454 - val_loss: 35.6421\n",
      "Epoch 225/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1331 - val_loss: 35.6760\n",
      "Epoch 226/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.1348 - val_loss: 35.6228\n",
      "Epoch 227/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1265 - val_loss: 35.5469\n",
      "Epoch 228/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1414 - val_loss: 35.4790\n",
      "Epoch 229/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1288 - val_loss: 35.4929\n",
      "Epoch 230/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1361 - val_loss: 35.5970\n",
      "Epoch 231/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1374 - val_loss: 35.5801\n",
      "Epoch 232/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1331 - val_loss: 35.6719\n",
      "Epoch 233/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.1407 - val_loss: 35.5674\n",
      "Epoch 234/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1234 - val_loss: 35.6349\n",
      "Epoch 235/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1354 - val_loss: 35.6495\n",
      "Epoch 236/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1332 - val_loss: 35.6116\n",
      "Epoch 237/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1304 - val_loss: 35.5833\n",
      "Epoch 238/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1296 - val_loss: 35.7712\n",
      "Epoch 239/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1352 - val_loss: 35.5478\n",
      "Epoch 240/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1264 - val_loss: 35.4990\n",
      "Epoch 241/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1280 - val_loss: 35.5853\n",
      "Epoch 242/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1322 - val_loss: 35.3594\n",
      "Epoch 243/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1244 - val_loss: 35.4176\n",
      "Epoch 244/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1192 - val_loss: 35.4718\n",
      "Epoch 245/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1271 - val_loss: 35.2848\n",
      "Epoch 246/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1158 - val_loss: 35.1778\n",
      "Epoch 247/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1184 - val_loss: 35.3656\n",
      "Epoch 248/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1237 - val_loss: 35.4741\n",
      "Epoch 249/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1322 - val_loss: 35.1518\n",
      "Epoch 250/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1264 - val_loss: 35.3338\n",
      "Epoch 251/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1195 - val_loss: 35.1723\n",
      "Epoch 252/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1223 - val_loss: 35.1217\n",
      "Epoch 253/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1145 - val_loss: 35.0935\n",
      "Epoch 254/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1241 - val_loss: 35.1396\n",
      "Epoch 255/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1167 - val_loss: 35.0599\n",
      "Epoch 256/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.1203 - val_loss: 35.1161\n",
      "Epoch 257/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1177 - val_loss: 35.0631\n",
      "Epoch 258/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1177 - val_loss: 34.9828\n",
      "Epoch 259/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.1227 - val_loss: 34.8782\n",
      "Epoch 260/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1192 - val_loss: 35.1232\n",
      "Epoch 261/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1100 - val_loss: 34.9644\n",
      "Epoch 262/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1114 - val_loss: 34.9416\n",
      "Epoch 263/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1149 - val_loss: 34.8210\n",
      "Epoch 264/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1151 - val_loss: 34.9003\n",
      "Epoch 265/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1151 - val_loss: 34.8208\n",
      "Epoch 266/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1135 - val_loss: 34.7039\n",
      "Epoch 267/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1029 - val_loss: 34.6505\n",
      "Epoch 268/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.1101 - val_loss: 34.7376\n",
      "Epoch 269/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1116 - val_loss: 34.7447\n",
      "Epoch 270/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1087 - val_loss: 34.6757\n",
      "Epoch 271/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1076 - val_loss: 34.6703\n",
      "Epoch 272/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1123 - val_loss: 34.7066\n",
      "Epoch 273/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1055 - val_loss: 34.4910\n",
      "Epoch 274/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1099 - val_loss: 34.6151\n",
      "Epoch 275/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1015 - val_loss: 34.3508\n",
      "Epoch 276/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1111 - val_loss: 34.5525\n",
      "Epoch 277/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1101 - val_loss: 34.5800\n",
      "Epoch 278/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1108 - val_loss: 34.3557\n",
      "Epoch 279/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1080 - val_loss: 34.3740\n",
      "Epoch 280/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.1104 - val_loss: 34.4021\n",
      "Epoch 281/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.1050 - val_loss: 34.2373\n",
      "Epoch 282/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1054 - val_loss: 34.1206\n",
      "Epoch 283/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1048 - val_loss: 34.2183\n",
      "Epoch 284/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1029 - val_loss: 34.2102\n",
      "Epoch 285/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1103 - val_loss: 34.2754\n",
      "Epoch 286/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.1042 - val_loss: 34.2037\n",
      "Epoch 287/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1082 - val_loss: 33.9433\n",
      "Epoch 288/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0955 - val_loss: 33.9990\n",
      "Epoch 289/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0984 - val_loss: 33.8785\n",
      "Epoch 290/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0983 - val_loss: 33.9868\n",
      "Epoch 291/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0995 - val_loss: 33.8405\n",
      "Epoch 292/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0971 - val_loss: 34.0960\n",
      "Epoch 293/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0965 - val_loss: 33.8360\n",
      "Epoch 294/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.1010 - val_loss: 34.0000\n",
      "Epoch 295/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0999 - val_loss: 33.9293\n",
      "Epoch 296/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.1004 - val_loss: 33.8028\n",
      "Epoch 297/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0852 - val_loss: 33.6108\n",
      "Epoch 298/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0949 - val_loss: 33.7698\n",
      "Epoch 299/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0920 - val_loss: 33.8021\n",
      "Epoch 300/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0948 - val_loss: 33.8375\n",
      "Epoch 301/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0915 - val_loss: 33.6685\n",
      "Epoch 302/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0917 - val_loss: 33.6182\n",
      "Epoch 303/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0847 - val_loss: 33.8837\n",
      "Epoch 304/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0965 - val_loss: 33.7054\n",
      "Epoch 305/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0963 - val_loss: 33.7477\n",
      "Epoch 306/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0887 - val_loss: 33.5411\n",
      "Epoch 307/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0955 - val_loss: 33.5962\n",
      "Epoch 308/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0907 - val_loss: 33.4717\n",
      "Epoch 309/1000\n",
      "116721/116721 [==============================] - 8s 72us/sample - loss: 5.0838 - val_loss: 33.6483\n",
      "Epoch 310/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0919 - val_loss: 33.6738\n",
      "Epoch 311/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0814 - val_loss: 33.5530\n",
      "Epoch 312/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0890 - val_loss: 33.6138\n",
      "Epoch 313/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0889 - val_loss: 33.4421\n",
      "Epoch 314/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0854 - val_loss: 33.4925\n",
      "Epoch 315/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0905 - val_loss: 33.4969\n",
      "Epoch 316/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0879 - val_loss: 33.5539\n",
      "Epoch 317/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0866 - val_loss: 33.5187\n",
      "Epoch 318/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0853 - val_loss: 33.3752\n",
      "Epoch 319/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.0849 - val_loss: 33.6316\n",
      "Epoch 320/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0891 - val_loss: 33.4696\n",
      "Epoch 321/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0858 - val_loss: 33.4938\n",
      "Epoch 322/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0769 - val_loss: 33.3890\n",
      "Epoch 323/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0801 - val_loss: 33.3373\n",
      "Epoch 324/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0858 - val_loss: 33.5410\n",
      "Epoch 325/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0851 - val_loss: 33.5773\n",
      "Epoch 326/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0758 - val_loss: 33.5458\n",
      "Epoch 327/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0748 - val_loss: 33.7163\n",
      "Epoch 328/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0819 - val_loss: 33.5218\n",
      "Epoch 329/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0723 - val_loss: 33.4430\n",
      "Epoch 330/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0763 - val_loss: 33.4700\n",
      "Epoch 331/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0784 - val_loss: 33.5105\n",
      "Epoch 332/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.0714 - val_loss: 33.3969\n",
      "Epoch 333/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0767 - val_loss: 33.4734\n",
      "Epoch 334/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0702 - val_loss: 33.4250\n",
      "Epoch 335/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0706 - val_loss: 33.7124\n",
      "Epoch 336/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0671 - val_loss: 33.5063\n",
      "Epoch 337/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0785 - val_loss: 33.3749\n",
      "Epoch 338/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0669 - val_loss: 33.2651\n",
      "Epoch 339/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0656 - val_loss: 33.3042\n",
      "Epoch 340/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0681 - val_loss: 33.6730\n",
      "Epoch 341/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0707 - val_loss: 33.4823\n",
      "Epoch 342/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0687 - val_loss: 33.4694\n",
      "Epoch 343/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0668 - val_loss: 33.6140\n",
      "Epoch 344/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0669 - val_loss: 33.6001\n",
      "Epoch 345/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0660 - val_loss: 33.6076\n",
      "Epoch 346/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0610 - val_loss: 33.7199\n",
      "Epoch 347/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0614 - val_loss: 33.7670\n",
      "Epoch 348/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0618 - val_loss: 33.9549\n",
      "Epoch 349/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0589 - val_loss: 33.8324\n",
      "Epoch 350/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0572 - val_loss: 33.8546\n",
      "Epoch 351/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0605 - val_loss: 33.6493\n",
      "Epoch 352/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0532 - val_loss: 33.8526\n",
      "Epoch 353/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0471 - val_loss: 33.9475\n",
      "Epoch 354/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0574 - val_loss: 34.1141\n",
      "Epoch 355/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0551 - val_loss: 34.1088\n",
      "Epoch 356/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.0529 - val_loss: 34.1062\n",
      "Epoch 357/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0519 - val_loss: 34.3490\n",
      "Epoch 358/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0492 - val_loss: 34.2308\n",
      "Epoch 359/1000\n",
      "116721/116721 [==============================] - 8s 72us/sample - loss: 5.0512 - val_loss: 34.0852\n",
      "Epoch 360/1000\n",
      "116721/116721 [==============================] - 8s 72us/sample - loss: 5.0478 - val_loss: 34.3051\n",
      "Epoch 361/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0551 - val_loss: 34.2157\n",
      "Epoch 362/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0554 - val_loss: 34.4145\n",
      "Epoch 363/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0509 - val_loss: 34.5510\n",
      "Epoch 364/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0512 - val_loss: 34.6255\n",
      "Epoch 365/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0562 - val_loss: 34.7552\n",
      "Epoch 366/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0439 - val_loss: 34.7244\n",
      "Epoch 367/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0427 - val_loss: 34.7588\n",
      "Epoch 368/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0426 - val_loss: 34.9643\n",
      "Epoch 369/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0455 - val_loss: 34.9885\n",
      "Epoch 370/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0441 - val_loss: 35.1677\n",
      "Epoch 371/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0434 - val_loss: 35.0314\n",
      "Epoch 372/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0421 - val_loss: 34.8104\n",
      "Epoch 373/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.0484 - val_loss: 35.0848\n",
      "Epoch 374/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.0383 - val_loss: 35.0807\n",
      "Epoch 375/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0385 - val_loss: 35.2433\n",
      "Epoch 376/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0420 - val_loss: 35.3518\n",
      "Epoch 377/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0393 - val_loss: 35.3157\n",
      "Epoch 378/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0389 - val_loss: 35.4249\n",
      "Epoch 379/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.0415 - val_loss: 35.5318\n",
      "Epoch 380/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0438 - val_loss: 35.5320\n",
      "Epoch 381/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.0350 - val_loss: 35.5977\n",
      "Epoch 382/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0394 - val_loss: 35.6334\n",
      "Epoch 383/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0357 - val_loss: 35.6931\n",
      "Epoch 384/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0320 - val_loss: 35.8783\n",
      "Epoch 385/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0295 - val_loss: 35.8678\n",
      "Epoch 386/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0365 - val_loss: 35.8347\n",
      "Epoch 387/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0389 - val_loss: 36.0519\n",
      "Epoch 388/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0349 - val_loss: 36.1002\n",
      "Epoch 389/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0354 - val_loss: 36.0097\n",
      "Epoch 390/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0355 - val_loss: 36.2124\n",
      "Epoch 391/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0364 - val_loss: 36.1620\n",
      "Epoch 392/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0338 - val_loss: 36.1711\n",
      "Epoch 393/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0316 - val_loss: 36.2503\n",
      "Epoch 394/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0272 - val_loss: 36.3297\n",
      "Epoch 395/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0305 - val_loss: 36.5100\n",
      "Epoch 396/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0292 - val_loss: 36.4448\n",
      "Epoch 397/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0354 - val_loss: 36.5700\n",
      "Epoch 398/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0285 - val_loss: 36.8229\n",
      "Epoch 399/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0341 - val_loss: 36.8050\n",
      "Epoch 400/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0315 - val_loss: 37.0663\n",
      "Epoch 401/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0348 - val_loss: 36.9733\n",
      "Epoch 402/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0303 - val_loss: 36.9687\n",
      "Epoch 403/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0264 - val_loss: 37.1420\n",
      "Epoch 404/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0362 - val_loss: 37.0090\n",
      "Epoch 405/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0256 - val_loss: 37.0040\n",
      "Epoch 406/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0276 - val_loss: 37.0989\n",
      "Epoch 407/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0251 - val_loss: 37.2598\n",
      "Epoch 408/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0339 - val_loss: 37.3196\n",
      "Epoch 409/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0329 - val_loss: 37.3939\n",
      "Epoch 410/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0308 - val_loss: 37.5943\n",
      "Epoch 411/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0286 - val_loss: 37.6328\n",
      "Epoch 412/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0270 - val_loss: 37.7510\n",
      "Epoch 413/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0257 - val_loss: 37.6553\n",
      "Epoch 414/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0277 - val_loss: 37.7554\n",
      "Epoch 415/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0272 - val_loss: 37.9501\n",
      "Epoch 416/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0249 - val_loss: 38.2548\n",
      "Epoch 417/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0300 - val_loss: 38.2494\n",
      "Epoch 418/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0274 - val_loss: 38.1691\n",
      "Epoch 419/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0221 - val_loss: 38.1393\n",
      "Epoch 420/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0276 - val_loss: 38.2791\n",
      "Epoch 421/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0242 - val_loss: 38.3955\n",
      "Epoch 422/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0213 - val_loss: 38.3141\n",
      "Epoch 423/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0228 - val_loss: 38.6625\n",
      "Epoch 424/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0147 - val_loss: 38.9822\n",
      "Epoch 425/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.0243 - val_loss: 39.0465\n",
      "Epoch 426/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0172 - val_loss: 39.0717\n",
      "Epoch 427/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0201 - val_loss: 39.2424\n",
      "Epoch 428/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0170 - val_loss: 39.1850\n",
      "Epoch 429/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0235 - val_loss: 39.1057\n",
      "Epoch 430/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0224 - val_loss: 39.0559\n",
      "Epoch 431/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0292 - val_loss: 39.5780\n",
      "Epoch 432/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0193 - val_loss: 39.8613\n",
      "Epoch 433/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0116 - val_loss: 39.7584\n",
      "Epoch 434/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0186 - val_loss: 39.5004\n",
      "Epoch 435/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0178 - val_loss: 39.5721\n",
      "Epoch 436/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0189 - val_loss: 39.6321\n",
      "Epoch 437/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0134 - val_loss: 39.6010\n",
      "Epoch 438/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0227 - val_loss: 39.4418\n",
      "Epoch 439/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0181 - val_loss: 39.4009\n",
      "Epoch 440/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.0187 - val_loss: 39.2975\n",
      "Epoch 441/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0157 - val_loss: 39.3676\n",
      "Epoch 442/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0162 - val_loss: 39.6632\n",
      "Epoch 443/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0230 - val_loss: 39.7051\n",
      "Epoch 444/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0186 - val_loss: 39.8631\n",
      "Epoch 445/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0202 - val_loss: 39.9818\n",
      "Epoch 446/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0171 - val_loss: 40.3374\n",
      "Epoch 447/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.0186 - val_loss: 40.2102\n",
      "Epoch 448/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0120 - val_loss: 40.2376\n",
      "Epoch 449/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0162 - val_loss: 40.2796\n",
      "Epoch 450/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0155 - val_loss: 40.7886\n",
      "Epoch 451/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0198 - val_loss: 40.5265\n",
      "Epoch 452/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0164 - val_loss: 40.7117\n",
      "Epoch 453/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0177 - val_loss: 40.5027\n",
      "Epoch 454/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0190 - val_loss: 40.4894\n",
      "Epoch 455/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0217 - val_loss: 40.5306\n",
      "Epoch 456/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0116 - val_loss: 40.8357\n",
      "Epoch 457/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0185 - val_loss: 40.7448\n",
      "Epoch 458/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0144 - val_loss: 41.0168\n",
      "Epoch 459/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0092 - val_loss: 41.1075\n",
      "Epoch 460/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0062 - val_loss: 41.0378\n",
      "Epoch 461/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0076 - val_loss: 41.1127\n",
      "Epoch 462/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0102 - val_loss: 41.5853\n",
      "Epoch 463/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0059 - val_loss: 41.8251\n",
      "Epoch 464/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0132 - val_loss: 42.2805\n",
      "Epoch 465/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0173 - val_loss: 42.4141\n",
      "Epoch 466/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0165 - val_loss: 43.2145\n",
      "Epoch 467/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0088 - val_loss: 42.4868\n",
      "Epoch 468/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0023 - val_loss: 42.3863\n",
      "Epoch 469/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0041 - val_loss: 42.6646\n",
      "Epoch 470/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0064 - val_loss: 43.2783\n",
      "Epoch 471/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0119 - val_loss: 43.4679\n",
      "Epoch 472/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0153 - val_loss: 43.9424\n",
      "Epoch 473/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0051 - val_loss: 44.3365\n",
      "Epoch 474/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0063 - val_loss: 46.4840\n",
      "Epoch 475/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0060 - val_loss: 46.3500\n",
      "Epoch 476/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0035 - val_loss: 45.5469\n",
      "Epoch 477/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0086 - val_loss: 45.7673\n",
      "Epoch 478/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.0109 - val_loss: 45.0279\n",
      "Epoch 479/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0099 - val_loss: 45.9471\n",
      "Epoch 480/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9999 - val_loss: 46.7174\n",
      "Epoch 481/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0087 - val_loss: 47.1584\n",
      "Epoch 482/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0055 - val_loss: 47.2598\n",
      "Epoch 483/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0040 - val_loss: 46.9469\n",
      "Epoch 484/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 5.0067 - val_loss: 46.9184\n",
      "Epoch 485/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0057 - val_loss: 48.1578\n",
      "Epoch 486/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0056 - val_loss: 48.1527\n",
      "Epoch 487/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0059 - val_loss: 48.2835\n",
      "Epoch 488/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0068 - val_loss: 48.0625\n",
      "Epoch 489/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0017 - val_loss: 49.4340\n",
      "Epoch 490/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0048 - val_loss: 49.8018\n",
      "Epoch 491/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0004 - val_loss: 49.7708\n",
      "Epoch 492/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9997 - val_loss: 49.4254\n",
      "Epoch 493/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0012 - val_loss: 49.8376\n",
      "Epoch 494/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9956 - val_loss: 49.8918\n",
      "Epoch 495/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0051 - val_loss: 48.4092\n",
      "Epoch 496/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0059 - val_loss: 48.3642\n",
      "Epoch 497/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0009 - val_loss: 48.8831\n",
      "Epoch 498/1000\n",
      "116721/116721 [==============================] - 8s 66us/sample - loss: 5.0087 - val_loss: 49.0791\n",
      "Epoch 499/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9980 - val_loss: 49.6668\n",
      "Epoch 500/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0016 - val_loss: 50.6142\n",
      "Epoch 501/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0069 - val_loss: 51.9261\n",
      "Epoch 502/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0065 - val_loss: 52.0088\n",
      "Epoch 503/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0040 - val_loss: 50.9876\n",
      "Epoch 504/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0023 - val_loss: 49.5350\n",
      "Epoch 505/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0031 - val_loss: 51.2729\n",
      "Epoch 506/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0023 - val_loss: 53.2166\n",
      "Epoch 507/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9990 - val_loss: 52.2134\n",
      "Epoch 508/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0079 - val_loss: 52.8516\n",
      "Epoch 509/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 5.0002 - val_loss: 53.7488\n",
      "Epoch 510/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0000 - val_loss: 55.9505\n",
      "Epoch 511/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9947 - val_loss: 52.6207\n",
      "Epoch 512/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0019 - val_loss: 56.1544\n",
      "Epoch 513/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0013 - val_loss: 57.3942\n",
      "Epoch 514/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0045 - val_loss: 57.5977\n",
      "Epoch 515/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9994 - val_loss: 58.1795\n",
      "Epoch 516/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0041 - val_loss: 57.0491\n",
      "Epoch 517/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9976 - val_loss: 56.6542\n",
      "Epoch 518/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0051 - val_loss: 58.5816\n",
      "Epoch 519/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9991 - val_loss: 60.7810\n",
      "Epoch 520/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0005 - val_loss: 60.0937\n",
      "Epoch 521/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9981 - val_loss: 60.4796\n",
      "Epoch 522/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9952 - val_loss: 63.2608\n",
      "Epoch 523/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0005 - val_loss: 63.3608\n",
      "Epoch 524/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0002 - val_loss: 63.4382\n",
      "Epoch 525/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9976 - val_loss: 65.1429\n",
      "Epoch 526/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0016 - val_loss: 67.1839\n",
      "Epoch 527/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9978 - val_loss: 65.3211\n",
      "Epoch 528/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9975 - val_loss: 70.2822\n",
      "Epoch 529/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9953 - val_loss: 68.9869\n",
      "Epoch 530/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0012 - val_loss: 69.4725\n",
      "Epoch 531/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 5.0032 - val_loss: 67.8535\n",
      "Epoch 532/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9938 - val_loss: 70.8226\n",
      "Epoch 533/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0008 - val_loss: 69.9407\n",
      "Epoch 534/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9963 - val_loss: 72.0274\n",
      "Epoch 535/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9955 - val_loss: 71.3162\n",
      "Epoch 536/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9954 - val_loss: 67.5368\n",
      "Epoch 537/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9921 - val_loss: 70.9234\n",
      "Epoch 538/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9955 - val_loss: 71.6369\n",
      "Epoch 539/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9938 - val_loss: 69.2316\n",
      "Epoch 540/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9956 - val_loss: 70.2303\n",
      "Epoch 541/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9983 - val_loss: 76.3268\n",
      "Epoch 542/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9986 - val_loss: 72.4531\n",
      "Epoch 543/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9941 - val_loss: 81.5754\n",
      "Epoch 544/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9952 - val_loss: 79.3083\n",
      "Epoch 545/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9987 - val_loss: 76.5105\n",
      "Epoch 546/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9957 - val_loss: 73.4866\n",
      "Epoch 547/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9902 - val_loss: 74.6032\n",
      "Epoch 548/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9950 - val_loss: 77.4178\n",
      "Epoch 549/1000\n",
      "116721/116721 [==============================] - 8s 66us/sample - loss: 4.9928 - val_loss: 82.8208\n",
      "Epoch 550/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9933 - val_loss: 82.6276\n",
      "Epoch 551/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9937 - val_loss: 76.8288\n",
      "Epoch 552/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0014 - val_loss: 72.2885\n",
      "Epoch 553/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9879 - val_loss: 72.0068\n",
      "Epoch 554/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9851 - val_loss: 72.1209\n",
      "Epoch 555/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9980 - val_loss: 74.2646\n",
      "Epoch 556/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 5.0002 - val_loss: 69.5200\n",
      "Epoch 557/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9902 - val_loss: 71.2547\n",
      "Epoch 558/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9940 - val_loss: 68.1710\n",
      "Epoch 559/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9953 - val_loss: 71.2284\n",
      "Epoch 560/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9911 - val_loss: 66.3790\n",
      "Epoch 561/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9927 - val_loss: 64.2471\n",
      "Epoch 562/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9856 - val_loss: 65.7166\n",
      "Epoch 563/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9900 - val_loss: 65.2294\n",
      "Epoch 564/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9868 - val_loss: 65.9806\n",
      "Epoch 565/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9886 - val_loss: 61.3556\n",
      "Epoch 566/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9871 - val_loss: 61.7248\n",
      "Epoch 567/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9946 - val_loss: 62.4504\n",
      "Epoch 568/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9852 - val_loss: 64.8226\n",
      "Epoch 569/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9892 - val_loss: 64.4469\n",
      "Epoch 570/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9921 - val_loss: 64.5848\n",
      "Epoch 571/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9924 - val_loss: 62.6375\n",
      "Epoch 572/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9918 - val_loss: 61.7708\n",
      "Epoch 573/1000\n",
      "116721/116721 [==============================] - 8s 66us/sample - loss: 4.9944 - val_loss: 62.7749\n",
      "Epoch 574/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9989 - val_loss: 59.3042\n",
      "Epoch 575/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9863 - val_loss: 60.3883\n",
      "Epoch 576/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9874 - val_loss: 59.6246\n",
      "Epoch 577/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9880 - val_loss: 62.5204\n",
      "Epoch 578/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9834 - val_loss: 59.3102\n",
      "Epoch 579/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 5.0011 - val_loss: 60.0613\n",
      "Epoch 580/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9870 - val_loss: 57.9370\n",
      "Epoch 581/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9959 - val_loss: 57.0052\n",
      "Epoch 582/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9837 - val_loss: 59.0964\n",
      "Epoch 583/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9854 - val_loss: 57.9633\n",
      "Epoch 584/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9834 - val_loss: 57.5389\n",
      "Epoch 585/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9855 - val_loss: 60.0009\n",
      "Epoch 586/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9831 - val_loss: 56.7510\n",
      "Epoch 587/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9927 - val_loss: 53.2240\n",
      "Epoch 588/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9841 - val_loss: 55.8529\n",
      "Epoch 589/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9854 - val_loss: 57.0674\n",
      "Epoch 590/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9834 - val_loss: 55.9761\n",
      "Epoch 591/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9884 - val_loss: 55.3308\n",
      "Epoch 592/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9873 - val_loss: 55.7265\n",
      "Epoch 593/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9897 - val_loss: 54.5430\n",
      "Epoch 594/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9811 - val_loss: 54.7097\n",
      "Epoch 595/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9826 - val_loss: 52.9071\n",
      "Epoch 596/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9904 - val_loss: 52.6887\n",
      "Epoch 597/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9819 - val_loss: 51.9890\n",
      "Epoch 598/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9870 - val_loss: 52.9113\n",
      "Epoch 599/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9815 - val_loss: 51.6734\n",
      "Epoch 600/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9860 - val_loss: 52.7532\n",
      "Epoch 601/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9879 - val_loss: 53.7424\n",
      "Epoch 602/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9878 - val_loss: 54.0850\n",
      "Epoch 603/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9777 - val_loss: 52.5879\n",
      "Epoch 604/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9799 - val_loss: 51.5155\n",
      "Epoch 605/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9796 - val_loss: 51.0343\n",
      "Epoch 606/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9807 - val_loss: 51.5835\n",
      "Epoch 607/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9851 - val_loss: 51.2489\n",
      "Epoch 608/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9834 - val_loss: 50.1199\n",
      "Epoch 609/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9844 - val_loss: 50.8386\n",
      "Epoch 610/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9844 - val_loss: 51.3239\n",
      "Epoch 611/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9780 - val_loss: 49.5657\n",
      "Epoch 612/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9879 - val_loss: 47.4045\n",
      "Epoch 613/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9874 - val_loss: 47.3303\n",
      "Epoch 614/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9847 - val_loss: 48.9656\n",
      "Epoch 615/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9791 - val_loss: 49.2833\n",
      "Epoch 616/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9791 - val_loss: 49.1161\n",
      "Epoch 617/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9832 - val_loss: 47.8440\n",
      "Epoch 618/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9864 - val_loss: 48.3320\n",
      "Epoch 619/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9845 - val_loss: 48.6936\n",
      "Epoch 620/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9825 - val_loss: 48.2048\n",
      "Epoch 621/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9811 - val_loss: 47.8724\n",
      "Epoch 622/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9853 - val_loss: 48.2977\n",
      "Epoch 623/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9790 - val_loss: 48.3437\n",
      "Epoch 624/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9845 - val_loss: 47.5129\n",
      "Epoch 625/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9791 - val_loss: 47.0885\n",
      "Epoch 626/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9789 - val_loss: 47.0079\n",
      "Epoch 627/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9878 - val_loss: 47.2482\n",
      "Epoch 628/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9826 - val_loss: 47.3265\n",
      "Epoch 629/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9804 - val_loss: 46.6705\n",
      "Epoch 630/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9784 - val_loss: 47.6504\n",
      "Epoch 631/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9813 - val_loss: 46.2778\n",
      "Epoch 632/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9700 - val_loss: 47.5928\n",
      "Epoch 633/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9811 - val_loss: 46.5578\n",
      "Epoch 634/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9745 - val_loss: 46.2474\n",
      "Epoch 635/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9804 - val_loss: 45.7631\n",
      "Epoch 636/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9871 - val_loss: 46.3465\n",
      "Epoch 637/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9717 - val_loss: 45.4737\n",
      "Epoch 638/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9838 - val_loss: 45.6330\n",
      "Epoch 639/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9761 - val_loss: 45.3060\n",
      "Epoch 640/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9807 - val_loss: 44.6039\n",
      "Epoch 641/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9877 - val_loss: 44.5286\n",
      "Epoch 642/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9769 - val_loss: 43.5568\n",
      "Epoch 643/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9756 - val_loss: 43.8819\n",
      "Epoch 644/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9804 - val_loss: 43.3566\n",
      "Epoch 645/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9813 - val_loss: 43.6384\n",
      "Epoch 646/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9747 - val_loss: 43.0880\n",
      "Epoch 647/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9772 - val_loss: 42.8143\n",
      "Epoch 648/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9805 - val_loss: 42.4972\n",
      "Epoch 649/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9808 - val_loss: 42.5003\n",
      "Epoch 650/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9804 - val_loss: 42.3161\n",
      "Epoch 651/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9759 - val_loss: 42.1899\n",
      "Epoch 652/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9800 - val_loss: 42.2443\n",
      "Epoch 653/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9775 - val_loss: 42.3743\n",
      "Epoch 654/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9804 - val_loss: 42.2625\n",
      "Epoch 655/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9802 - val_loss: 41.6781\n",
      "Epoch 656/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9751 - val_loss: 41.8884\n",
      "Epoch 657/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9798 - val_loss: 41.5168\n",
      "Epoch 658/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9796 - val_loss: 42.0123\n",
      "Epoch 659/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9802 - val_loss: 41.6739\n",
      "Epoch 660/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9815 - val_loss: 41.9153\n",
      "Epoch 661/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9702 - val_loss: 41.9783\n",
      "Epoch 662/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9814 - val_loss: 41.8660\n",
      "Epoch 663/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9703 - val_loss: 41.6733\n",
      "Epoch 664/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9749 - val_loss: 41.3691\n",
      "Epoch 665/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9727 - val_loss: 41.4735\n",
      "Epoch 666/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9801 - val_loss: 41.0897\n",
      "Epoch 667/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9754 - val_loss: 40.9963\n",
      "Epoch 668/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9691 - val_loss: 40.9346\n",
      "Epoch 669/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9784 - val_loss: 40.9264\n",
      "Epoch 670/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9686 - val_loss: 40.8007\n",
      "Epoch 671/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9774 - val_loss: 40.6698\n",
      "Epoch 672/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9772 - val_loss: 40.2745\n",
      "Epoch 673/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9708 - val_loss: 40.6168\n",
      "Epoch 674/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9786 - val_loss: 40.3891\n",
      "Epoch 675/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9762 - val_loss: 40.3023\n",
      "Epoch 676/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9819 - val_loss: 40.1758\n",
      "Epoch 677/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9727 - val_loss: 40.2973\n",
      "Epoch 678/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9765 - val_loss: 40.2135\n",
      "Epoch 679/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9809 - val_loss: 40.1815\n",
      "Epoch 680/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9792 - val_loss: 40.1919\n",
      "Epoch 681/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9730 - val_loss: 40.1620\n",
      "Epoch 682/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9760 - val_loss: 40.1410\n",
      "Epoch 683/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9833 - val_loss: 40.0331\n",
      "Epoch 684/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9810 - val_loss: 39.8906\n",
      "Epoch 685/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9728 - val_loss: 39.7542\n",
      "Epoch 686/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9683 - val_loss: 39.8201\n",
      "Epoch 687/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9747 - val_loss: 39.8337\n",
      "Epoch 688/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9697 - val_loss: 39.8988\n",
      "Epoch 689/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9731 - val_loss: 40.0449\n",
      "Epoch 690/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9677 - val_loss: 40.0897\n",
      "Epoch 691/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9812 - val_loss: 40.1381\n",
      "Epoch 692/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9694 - val_loss: 39.9589\n",
      "Epoch 693/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9755 - val_loss: 39.9532\n",
      "Epoch 694/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9727 - val_loss: 39.9554\n",
      "Epoch 695/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9802 - val_loss: 39.8505\n",
      "Epoch 696/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9716 - val_loss: 39.9311\n",
      "Epoch 697/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9735 - val_loss: 39.8239\n",
      "Epoch 698/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9799 - val_loss: 39.8920\n",
      "Epoch 699/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9715 - val_loss: 39.8746\n",
      "Epoch 700/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9668 - val_loss: 39.9436\n",
      "Epoch 701/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9703 - val_loss: 39.7716\n",
      "Epoch 702/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9721 - val_loss: 39.7921\n",
      "Epoch 703/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9703 - val_loss: 39.8330\n",
      "Epoch 704/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9785 - val_loss: 39.7531\n",
      "Epoch 705/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9692 - val_loss: 39.6302\n",
      "Epoch 706/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9630 - val_loss: 39.5715\n",
      "Epoch 707/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9664 - val_loss: 39.6235\n",
      "Epoch 708/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9748 - val_loss: 39.6638\n",
      "Epoch 709/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9712 - val_loss: 39.6103\n",
      "Epoch 710/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9713 - val_loss: 39.6222\n",
      "Epoch 711/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9741 - val_loss: 39.5392\n",
      "Epoch 712/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9646 - val_loss: 39.5272\n",
      "Epoch 713/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9648 - val_loss: 39.6065\n",
      "Epoch 714/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9673 - val_loss: 39.4331\n",
      "Epoch 715/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9668 - val_loss: 39.3500\n",
      "Epoch 716/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9736 - val_loss: 39.4672\n",
      "Epoch 717/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9740 - val_loss: 39.4826\n",
      "Epoch 718/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9723 - val_loss: 39.5986\n",
      "Epoch 719/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9644 - val_loss: 39.4368\n",
      "Epoch 720/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9682 - val_loss: 39.1955\n",
      "Epoch 721/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9700 - val_loss: 39.3955\n",
      "Epoch 722/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9700 - val_loss: 39.2678\n",
      "Epoch 723/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9698 - val_loss: 39.1195\n",
      "Epoch 724/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9659 - val_loss: 39.2921\n",
      "Epoch 725/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9694 - val_loss: 39.4189\n",
      "Epoch 726/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9711 - val_loss: 39.3894\n",
      "Epoch 727/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9648 - val_loss: 39.3507\n",
      "Epoch 728/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9732 - val_loss: 39.3509\n",
      "Epoch 729/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9666 - val_loss: 39.4671\n",
      "Epoch 730/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9713 - val_loss: 39.2908\n",
      "Epoch 731/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9755 - val_loss: 39.1898\n",
      "Epoch 732/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9730 - val_loss: 39.3754\n",
      "Epoch 733/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9751 - val_loss: 39.1724\n",
      "Epoch 734/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9625 - val_loss: 39.3564\n",
      "Epoch 735/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9755 - val_loss: 39.4051\n",
      "Epoch 736/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9692 - val_loss: 39.4286\n",
      "Epoch 737/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9633 - val_loss: 39.3118\n",
      "Epoch 738/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9575 - val_loss: 39.2524\n",
      "Epoch 739/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9639 - val_loss: 39.1718\n",
      "Epoch 740/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9641 - val_loss: 39.3944\n",
      "Epoch 741/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9620 - val_loss: 39.2158\n",
      "Epoch 742/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9658 - val_loss: 39.2754\n",
      "Epoch 743/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9683 - val_loss: 39.0552\n",
      "Epoch 744/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9623 - val_loss: 39.3086\n",
      "Epoch 745/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9647 - val_loss: 39.2382\n",
      "Epoch 746/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9675 - val_loss: 39.2804\n",
      "Epoch 747/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9625 - val_loss: 39.1643\n",
      "Epoch 748/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9690 - val_loss: 39.1454\n",
      "Epoch 749/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9665 - val_loss: 39.2118\n",
      "Epoch 750/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9678 - val_loss: 39.0771\n",
      "Epoch 751/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9739 - val_loss: 39.1178\n",
      "Epoch 752/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9637 - val_loss: 39.2993\n",
      "Epoch 753/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9671 - val_loss: 39.0310\n",
      "Epoch 754/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9642 - val_loss: 39.1963\n",
      "Epoch 755/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9600 - val_loss: 39.1797\n",
      "Epoch 756/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9736 - val_loss: 39.0778\n",
      "Epoch 757/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9652 - val_loss: 39.0798\n",
      "Epoch 758/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9614 - val_loss: 39.1988\n",
      "Epoch 759/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9655 - val_loss: 39.1144\n",
      "Epoch 760/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9714 - val_loss: 38.9995\n",
      "Epoch 761/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9657 - val_loss: 39.1776\n",
      "Epoch 762/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9579 - val_loss: 39.0049\n",
      "Epoch 763/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9653 - val_loss: 38.9934\n",
      "Epoch 764/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9597 - val_loss: 39.1217\n",
      "Epoch 765/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9687 - val_loss: 39.1407\n",
      "Epoch 766/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9673 - val_loss: 39.0911\n",
      "Epoch 767/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9666 - val_loss: 39.0697\n",
      "Epoch 768/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9695 - val_loss: 39.2228\n",
      "Epoch 769/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9647 - val_loss: 39.1911\n",
      "Epoch 770/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9630 - val_loss: 39.2319\n",
      "Epoch 771/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9621 - val_loss: 39.2244\n",
      "Epoch 772/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9651 - val_loss: 39.3239\n",
      "Epoch 773/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9700 - val_loss: 39.2007\n",
      "Epoch 774/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9584 - val_loss: 39.2026\n",
      "Epoch 775/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9663 - val_loss: 39.2454\n",
      "Epoch 776/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9601 - val_loss: 38.8933\n",
      "Epoch 777/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9651 - val_loss: 39.0833\n",
      "Epoch 778/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9618 - val_loss: 39.3268\n",
      "Epoch 779/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9591 - val_loss: 39.1823\n",
      "Epoch 780/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9595 - val_loss: 39.2277\n",
      "Epoch 781/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9698 - val_loss: 39.2500\n",
      "Epoch 782/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9592 - val_loss: 39.3009\n",
      "Epoch 783/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9614 - val_loss: 39.3394\n",
      "Epoch 784/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9673 - val_loss: 39.2331\n",
      "Epoch 785/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9680 - val_loss: 39.3213\n",
      "Epoch 786/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9650 - val_loss: 39.2913\n",
      "Epoch 787/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9700 - val_loss: 39.1368\n",
      "Epoch 788/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9657 - val_loss: 39.2649\n",
      "Epoch 789/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9549 - val_loss: 39.3769\n",
      "Epoch 790/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9576 - val_loss: 39.1728\n",
      "Epoch 791/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9643 - val_loss: 39.3161\n",
      "Epoch 792/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9631 - val_loss: 39.4521\n",
      "Epoch 793/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9629 - val_loss: 39.3561\n",
      "Epoch 794/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9668 - val_loss: 39.0847\n",
      "Epoch 795/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9613 - val_loss: 39.3899\n",
      "Epoch 796/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9650 - val_loss: 39.2580\n",
      "Epoch 797/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9699 - val_loss: 39.1489\n",
      "Epoch 798/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9601 - val_loss: 39.2901\n",
      "Epoch 799/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9658 - val_loss: 39.2208\n",
      "Epoch 800/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9629 - val_loss: 39.2747\n",
      "Epoch 801/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9633 - val_loss: 39.2492\n",
      "Epoch 802/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9666 - val_loss: 39.3717\n",
      "Epoch 803/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9645 - val_loss: 39.3811\n",
      "Epoch 804/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9628 - val_loss: 39.3720\n",
      "Epoch 805/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9634 - val_loss: 39.2944\n",
      "Epoch 806/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9657 - val_loss: 39.1064\n",
      "Epoch 807/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9619 - val_loss: 39.1647\n",
      "Epoch 808/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9646 - val_loss: 39.2634\n",
      "Epoch 809/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9602 - val_loss: 39.1010\n",
      "Epoch 810/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9706 - val_loss: 39.1025\n",
      "Epoch 811/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9698 - val_loss: 39.1864\n",
      "Epoch 812/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9636 - val_loss: 39.1842\n",
      "Epoch 813/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9643 - val_loss: 39.4246\n",
      "Epoch 814/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9548 - val_loss: 39.3083\n",
      "Epoch 815/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9586 - val_loss: 39.1010\n",
      "Epoch 816/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9632 - val_loss: 39.2696\n",
      "Epoch 817/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9592 - val_loss: 39.2797\n",
      "Epoch 818/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9631 - val_loss: 39.2025\n",
      "Epoch 819/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9616 - val_loss: 39.5076\n",
      "Epoch 820/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9681 - val_loss: 39.4026\n",
      "Epoch 821/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9705 - val_loss: 39.3760\n",
      "Epoch 822/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9574 - val_loss: 39.4592\n",
      "Epoch 823/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9598 - val_loss: 39.3296\n",
      "Epoch 824/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9604 - val_loss: 39.4110\n",
      "Epoch 825/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9607 - val_loss: 39.1964\n",
      "Epoch 826/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9594 - val_loss: 39.3400\n",
      "Epoch 827/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9571 - val_loss: 39.3964\n",
      "Epoch 828/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9607 - val_loss: 39.3888\n",
      "Epoch 829/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9640 - val_loss: 39.4690\n",
      "Epoch 830/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9529 - val_loss: 39.4204\n",
      "Epoch 831/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9630 - val_loss: 39.4695\n",
      "Epoch 832/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9625 - val_loss: 39.3671\n",
      "Epoch 833/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9655 - val_loss: 39.5943\n",
      "Epoch 834/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9576 - val_loss: 39.2962\n",
      "Epoch 835/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9652 - val_loss: 39.5097\n",
      "Epoch 836/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9593 - val_loss: 39.3597\n",
      "Epoch 837/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9625 - val_loss: 39.5556\n",
      "Epoch 838/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9711 - val_loss: 39.5930\n",
      "Epoch 839/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9599 - val_loss: 39.4687\n",
      "Epoch 840/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9602 - val_loss: 39.4864\n",
      "Epoch 841/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9590 - val_loss: 39.4670\n",
      "Epoch 842/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9538 - val_loss: 39.2750\n",
      "Epoch 843/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9582 - val_loss: 39.4924\n",
      "Epoch 844/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9590 - val_loss: 39.4558\n",
      "Epoch 845/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9638 - val_loss: 39.4257\n",
      "Epoch 846/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9576 - val_loss: 39.4293\n",
      "Epoch 847/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9549 - val_loss: 39.3837\n",
      "Epoch 848/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9630 - val_loss: 39.3575\n",
      "Epoch 849/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9632 - val_loss: 39.2898\n",
      "Epoch 850/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9698 - val_loss: 39.4652\n",
      "Epoch 851/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9653 - val_loss: 39.6613\n",
      "Epoch 852/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9632 - val_loss: 39.3532\n",
      "Epoch 853/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9579 - val_loss: 39.3812\n",
      "Epoch 854/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9637 - val_loss: 39.4387\n",
      "Epoch 855/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9614 - val_loss: 39.6223\n",
      "Epoch 856/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9642 - val_loss: 39.5722\n",
      "Epoch 857/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9555 - val_loss: 39.5119\n",
      "Epoch 858/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9634 - val_loss: 39.6063\n",
      "Epoch 859/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9546 - val_loss: 39.5382\n",
      "Epoch 860/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9661 - val_loss: 39.7369\n",
      "Epoch 861/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9647 - val_loss: 39.6165\n",
      "Epoch 862/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9612 - val_loss: 39.5599\n",
      "Epoch 863/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9572 - val_loss: 39.4917\n",
      "Epoch 864/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9509 - val_loss: 39.4749\n",
      "Epoch 865/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9587 - val_loss: 39.5417\n",
      "Epoch 866/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9560 - val_loss: 39.6104\n",
      "Epoch 867/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9701 - val_loss: 39.6348\n",
      "Epoch 868/1000\n",
      "116721/116721 [==============================] - 8s 66us/sample - loss: 4.9571 - val_loss: 39.8403\n",
      "Epoch 869/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9512 - val_loss: 39.5155\n",
      "Epoch 870/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9593 - val_loss: 39.7077\n",
      "Epoch 871/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9602 - val_loss: 39.5536\n",
      "Epoch 872/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9565 - val_loss: 39.7936\n",
      "Epoch 873/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9577 - val_loss: 39.6464\n",
      "Epoch 874/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9553 - val_loss: 39.6034\n",
      "Epoch 875/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9603 - val_loss: 39.4501\n",
      "Epoch 876/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9624 - val_loss: 39.4945\n",
      "Epoch 877/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9575 - val_loss: 39.5805\n",
      "Epoch 878/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9560 - val_loss: 39.8186\n",
      "Epoch 879/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9596 - val_loss: 39.6196\n",
      "Epoch 880/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9457 - val_loss: 39.9142\n",
      "Epoch 881/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9605 - val_loss: 39.4829\n",
      "Epoch 882/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9581 - val_loss: 39.5787\n",
      "Epoch 883/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9577 - val_loss: 39.8268\n",
      "Epoch 884/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9607 - val_loss: 39.6270\n",
      "Epoch 885/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9589 - val_loss: 39.6528\n",
      "Epoch 886/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9560 - val_loss: 39.8994\n",
      "Epoch 887/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9608 - val_loss: 39.7174\n",
      "Epoch 888/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9544 - val_loss: 39.6582\n",
      "Epoch 889/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9554 - val_loss: 39.7054\n",
      "Epoch 890/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9591 - val_loss: 39.7190\n",
      "Epoch 891/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9580 - val_loss: 39.5383\n",
      "Epoch 892/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9587 - val_loss: 39.6886\n",
      "Epoch 893/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9597 - val_loss: 39.8396\n",
      "Epoch 894/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9573 - val_loss: 39.6817\n",
      "Epoch 895/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9527 - val_loss: 39.8436\n",
      "Epoch 896/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9645 - val_loss: 39.8186\n",
      "Epoch 897/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9592 - val_loss: 39.7184\n",
      "Epoch 898/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9551 - val_loss: 39.7323\n",
      "Epoch 899/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9628 - val_loss: 39.7671\n",
      "Epoch 900/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9593 - val_loss: 39.7099\n",
      "Epoch 901/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9525 - val_loss: 39.6779\n",
      "Epoch 902/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9558 - val_loss: 39.9073\n",
      "Epoch 903/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9561 - val_loss: 39.6947\n",
      "Epoch 904/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9550 - val_loss: 39.7879\n",
      "Epoch 905/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9556 - val_loss: 39.6765\n",
      "Epoch 906/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9596 - val_loss: 39.7672\n",
      "Epoch 907/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9547 - val_loss: 39.8852\n",
      "Epoch 908/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9562 - val_loss: 39.7324\n",
      "Epoch 909/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9507 - val_loss: 39.8469\n",
      "Epoch 910/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9548 - val_loss: 39.8288\n",
      "Epoch 911/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9559 - val_loss: 39.9058\n",
      "Epoch 912/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9468 - val_loss: 39.6752\n",
      "Epoch 913/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9557 - val_loss: 39.8222\n",
      "Epoch 914/1000\n",
      "116721/116721 [==============================] - 8s 72us/sample - loss: 4.9622 - val_loss: 39.9563\n",
      "Epoch 915/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9499 - val_loss: 39.8154\n",
      "Epoch 916/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9508 - val_loss: 39.6831\n",
      "Epoch 917/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9598 - val_loss: 39.8603\n",
      "Epoch 918/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9548 - val_loss: 39.7456\n",
      "Epoch 919/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9527 - val_loss: 39.7189\n",
      "Epoch 920/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9612 - val_loss: 39.7566\n",
      "Epoch 921/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9580 - val_loss: 39.7591\n",
      "Epoch 922/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9564 - val_loss: 39.8895\n",
      "Epoch 923/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9559 - val_loss: 39.7764\n",
      "Epoch 924/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9522 - val_loss: 39.8858\n",
      "Epoch 925/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9605 - val_loss: 39.7751\n",
      "Epoch 926/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9552 - val_loss: 39.7638\n",
      "Epoch 927/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9545 - val_loss: 39.8720\n",
      "Epoch 928/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9516 - val_loss: 39.8453\n",
      "Epoch 929/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9518 - val_loss: 39.7165\n",
      "Epoch 930/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9608 - val_loss: 39.7660\n",
      "Epoch 931/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9591 - val_loss: 39.7285\n",
      "Epoch 932/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9582 - val_loss: 39.6703\n",
      "Epoch 933/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9647 - val_loss: 39.7279\n",
      "Epoch 934/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9602 - val_loss: 39.7660\n",
      "Epoch 935/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9543 - val_loss: 39.7318\n",
      "Epoch 936/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9613 - val_loss: 39.7449\n",
      "Epoch 937/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9538 - val_loss: 39.7330\n",
      "Epoch 938/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9570 - val_loss: 39.8087\n",
      "Epoch 939/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9618 - val_loss: 39.7654\n",
      "Epoch 940/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9519 - val_loss: 39.9068\n",
      "Epoch 941/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9528 - val_loss: 39.8803\n",
      "Epoch 942/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9535 - val_loss: 39.8342\n",
      "Epoch 943/1000\n",
      "116721/116721 [==============================] - 8s 72us/sample - loss: 4.9593 - val_loss: 39.8195\n",
      "Epoch 944/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9528 - val_loss: 39.7726\n",
      "Epoch 945/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9549 - val_loss: 39.8200\n",
      "Epoch 946/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9540 - val_loss: 39.9482\n",
      "Epoch 947/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9575 - val_loss: 39.7383\n",
      "Epoch 948/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9484 - val_loss: 39.6899\n",
      "Epoch 949/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9519 - val_loss: 39.8091\n",
      "Epoch 950/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9488 - val_loss: 39.7821\n",
      "Epoch 951/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9519 - val_loss: 39.7743\n",
      "Epoch 952/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9509 - val_loss: 39.8045\n",
      "Epoch 953/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9597 - val_loss: 39.7686\n",
      "Epoch 954/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9521 - val_loss: 39.7242\n",
      "Epoch 955/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9569 - val_loss: 39.7455\n",
      "Epoch 956/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9530 - val_loss: 39.7663\n",
      "Epoch 957/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9503 - val_loss: 39.8867\n",
      "Epoch 958/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9518 - val_loss: 39.7307\n",
      "Epoch 959/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9575 - val_loss: 39.8540\n",
      "Epoch 960/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9522 - val_loss: 40.0041\n",
      "Epoch 961/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9492 - val_loss: 39.9141\n",
      "Epoch 962/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9541 - val_loss: 39.7803\n",
      "Epoch 963/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9525 - val_loss: 39.8297\n",
      "Epoch 964/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9466 - val_loss: 39.6442\n",
      "Epoch 965/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9519 - val_loss: 39.7173\n",
      "Epoch 966/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9496 - val_loss: 39.8090\n",
      "Epoch 967/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9490 - val_loss: 39.7442\n",
      "Epoch 968/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9498 - val_loss: 39.8799\n",
      "Epoch 969/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9568 - val_loss: 39.7736\n",
      "Epoch 970/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9580 - val_loss: 40.0470\n",
      "Epoch 971/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9493 - val_loss: 39.7568\n",
      "Epoch 972/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9479 - val_loss: 39.7754\n",
      "Epoch 973/1000\n",
      "116721/116721 [==============================] - 8s 68us/sample - loss: 4.9506 - val_loss: 39.9838\n",
      "Epoch 974/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9449 - val_loss: 40.0115\n",
      "Epoch 975/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9518 - val_loss: 39.8675\n",
      "Epoch 976/1000\n",
      "116721/116721 [==============================] - 8s 67us/sample - loss: 4.9525 - val_loss: 39.8258\n",
      "Epoch 977/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9554 - val_loss: 39.8489\n",
      "Epoch 978/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9560 - val_loss: 39.8466\n",
      "Epoch 979/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9630 - val_loss: 39.7994\n",
      "Epoch 980/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9538 - val_loss: 39.8403\n",
      "Epoch 981/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9595 - val_loss: 39.6950\n",
      "Epoch 982/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9494 - val_loss: 39.6295\n",
      "Epoch 983/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9577 - val_loss: 39.8521\n",
      "Epoch 984/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9474 - val_loss: 39.6094\n",
      "Epoch 985/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9548 - val_loss: 39.8108\n",
      "Epoch 986/1000\n",
      "116721/116721 [==============================] - 8s 71us/sample - loss: 4.9527 - val_loss: 39.6752\n",
      "Epoch 987/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9521 - val_loss: 39.7258\n",
      "Epoch 988/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9574 - val_loss: 39.8489\n",
      "Epoch 989/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9557 - val_loss: 39.6990\n",
      "Epoch 990/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9464 - val_loss: 39.6692\n",
      "Epoch 991/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9537 - val_loss: 39.7393\n",
      "Epoch 992/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9571 - val_loss: 39.8439\n",
      "Epoch 993/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9671 - val_loss: 39.8974\n",
      "Epoch 994/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9593 - val_loss: 39.7994\n",
      "Epoch 995/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9508 - val_loss: 39.8794\n",
      "Epoch 996/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9538 - val_loss: 39.8272\n",
      "Epoch 997/1000\n",
      "116721/116721 [==============================] - 8s 69us/sample - loss: 4.9518 - val_loss: 39.7220\n",
      "Epoch 998/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9529 - val_loss: 39.5542\n",
      "Epoch 999/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9497 - val_loss: 39.9776\n",
      "Epoch 1000/1000\n",
      "116721/116721 [==============================] - 8s 70us/sample - loss: 4.9549 - val_loss: 39.7847\n"
     ]
    }
   ],
   "source": [
    "vae.fit(x_train=x_train,epochs=1000,batch_size=32,validation_split=0.1,save_dir=\"output\",verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c5d584-1aa4-4139-b3d0-1768a284e2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41a160-62d1-4cef-b025-752e3a499cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a90f3-d48f-4d65-8744-2c2cbc36b9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
